{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Professional Emotion Detection Pipeline\n",
    "## Deep Learning for NLP - Emotion Classification in Twitter Text\n",
    "\n",
    "This notebook demonstrates a comprehensive, production-ready pipeline for emotion detection using LSTM and GRU neural networks.\n",
    "\n",
    "### Project Structure\n",
    "- **Data Processing**: Advanced text preprocessing with contraction expansion, typo correction\n",
    "- **Embeddings**: Support for both GloVe and Word2Vec\n",
    "- **Models**: LSTM, GRU, Bidirectional variants with configurable architectures\n",
    "- **Training**: Professional training pipeline with callbacks and experiment tracking\n",
    "- **Evaluation**: Comprehensive metrics and visualizations\n",
    "\n",
    "### Emotion Classes\n",
    "0. Sadness\n",
    "1. Joy\n",
    "2. Love\n",
    "3. Anger\n",
    "4. Fear\n",
    "5. Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import logging\n",
    "\n",
    "# Import custom modules\n",
    "from src.data.preprocessor import TextPreprocessor, load_and_preprocess_data\n",
    "from src.data.embeddings import EmbeddingHandler, create_embeddings\n",
    "from src.models.architectures import ModelBuilder, create_model\n",
    "from src.training.trainer import ModelTrainer, train_model\n",
    "from src.utils.visualization import ResultsVisualizer, create_comprehensive_report\n",
    "from src.utils.config import ExperimentConfig, get_all_configs\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = \"../data/raw\"\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VAL_PATH = os.path.join(DATA_DIR, \"validation.csv\")\n",
    "GLOVE_PATH = \"/home/lab/rabanof/Emotion_Detection_DL/glove/glove.6B.100d.txt\"\n",
    "\n",
    "# Emotion mapping\n",
    "EMOTION_MAP = {\n",
    "    0: 'Sadness', 1: 'Joy', 2: 'Love',\n",
    "    3: 'Anger', 4: 'Fear', 5: 'Surprise'\n",
    "}\n",
    "EMOTION_LABELS = list(EMOTION_MAP.values())\n",
    "\n",
    "# Create experiment configuration\n",
    "config = ExperimentConfig(\n",
    "    experiment_name=\"emotion_lstm_glove_v1\"\n",
    ")\n",
    "\n",
    "# Update paths in config\n",
    "config.data.train_path = TRAIN_PATH\n",
    "config.data.val_path = VAL_PATH\n",
    "config.embedding.embedding_path = GLOVE_PATH\n",
    "\n",
    "print(\"\\nExperiment Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Experiment Name: {config.experiment_name}\")\n",
    "print(f\"Model Type: {config.model.model_type.upper()}\")\n",
    "print(f\"Embedding: {config.embedding.embedding_type.upper()} (dim={config.embedding.embedding_dim})\")\n",
    "print(f\"Max Sequence Length: {config.data.max_len}\")\n",
    "print(f\"Vocabulary Size: {config.data.max_words}\")\n",
    "print(f\"Batch Size: {config.training.batch_size}\")\n",
    "print(f\"Epochs: {config.training.epochs}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "preprocessor = TextPreprocessor()\n",
    "train_df, val_df, preprocessor = load_and_preprocess_data(\n",
    "    TRAIN_PATH, VAL_PATH, preprocessor\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample preprocessed texts:\")\n",
    "for i, row in train_df.head(3).iterrows():\n",
    "    print(f\"[{EMOTION_MAP[row['label']]}] {row['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics\n",
    "train_stats = preprocessor.get_text_statistics(train_df)\n",
    "\n",
    "print(\"\\nTraining Data Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total samples: {train_stats['total_samples']}\")\n",
    "print(f\"Avg text length: {train_stats['avg_text_length']:.2f} words\")\n",
    "print(f\"Median text length: {train_stats['median_text_length']:.0f} words\")\n",
    "print(f\"Max text length: {train_stats['max_text_length']} words\")\n",
    "\n",
    "print(\"\\nLabel Distribution:\")\n",
    "for label, count in train_stats['label_distribution'].items():\n",
    "    pct = train_stats['label_percentages'][label]\n",
    "    print(f\"{EMOTION_MAP[label]:12s}: {count:5d} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Train distribution\n",
    "train_label_counts = train_df['label'].map(EMOTION_MAP).value_counts()\n",
    "axes[0].bar(train_label_counts.index, train_label_counts.values, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Training Set - Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Emotion')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Val distribution\n",
    "val_label_counts = val_df['label'].map(EMOTION_MAP).value_counts()\n",
    "axes[1].bar(val_label_counts.index, val_label_counts.values, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Validation Set - Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Emotion')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Text length distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(train_df['text_len'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(train_df['text_len'].mean(), color='red', linestyle='--', label=f'Mean: {train_df[\"text_len\"].mean():.1f}')\n",
    "plt.axvline(train_df['text_len'].median(), color='green', linestyle='--', label=f'Median: {train_df[\"text_len\"].median():.0f}')\n",
    "plt.title('Text Length Distribution (Training Set)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding handler\n",
    "embedding_handler = EmbeddingHandler(\n",
    "    embedding_type=config.embedding.embedding_type,\n",
    "    embedding_dim=config.embedding.embedding_dim,\n",
    "    max_words=config.data.max_words,\n",
    "    max_len=config.data.max_len\n",
    ")\n",
    "\n",
    "# Prepare sequences and embeddings\n",
    "X_train, X_val, embedding_matrix, stats = embedding_handler.prepare_sequences(\n",
    "    train_df['text'].tolist(),\n",
    "    val_df['text'].tolist(),\n",
    "    embedding_path=config.embedding.embedding_path\n",
    ")\n",
    "\n",
    "# Prepare labels\n",
    "y_train = to_categorical(train_df['label'].values, num_classes=6)\n",
    "y_val = to_categorical(val_df['label'].values, num_classes=6)\n",
    "\n",
    "print(\"\\nData Preparation Complete:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "print(f\"\\nEmbedding Coverage: {stats['coverage_percent']:.2f}%\")\n",
    "print(f\"Words found: {stats['words_found']}/{stats['total_words']}\")\n",
    "print(f\"Sample OOV words: {stats['sample_oov_words'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OOV rates\n",
    "train_oov_rate = embedding_handler.get_oov_rate(X_train)\n",
    "val_oov_rate = embedding_handler.get_oov_rate(X_val)\n",
    "\n",
    "print(f\"\\nOOV Token Rates:\")\n",
    "print(f\"Training set: {train_oov_rate:.2f}%\")\n",
    "print(f\"Validation set: {val_oov_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Weights Calculation\n",
    "\n",
    "To handle class imbalance, we compute class weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "if config.training.use_class_weights:\n",
    "    class_weights = preprocessor.compute_class_weights(train_df['label'].values)\n",
    "    print(\"\\nClass Weights:\")\n",
    "    for label, weight in class_weights.items():\n",
    "        print(f\"{EMOTION_MAP[label]:12s}: {weight:.3f}\")\n",
    "else:\n",
    "    class_weights = None\n",
    "    print(\"\\nClass weights disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model configuration dictionary\n",
    "model_config = {\n",
    "    # Architecture\n",
    "    'lstm_units' if config.model.model_type == 'lstm' else 'gru_units': config.model.units,\n",
    "    'num_layers': config.model.num_layers,\n",
    "    'dropout': config.model.dropout,\n",
    "    'recurrent_dropout': config.model.recurrent_dropout,\n",
    "    'spatial_dropout': config.model.spatial_dropout,\n",
    "    'bidirectional': config.model.bidirectional,\n",
    "    'dense_units': config.model.dense_units,\n",
    "    'trainable_embeddings': config.embedding.trainable,\n",
    "    \n",
    "    # Compilation\n",
    "    'learning_rate': config.training.learning_rate,\n",
    "    'optimizer': config.training.optimizer,\n",
    "    'loss': config.training.loss,\n",
    "    'metrics': ['accuracy']\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    model_type=config.model.model_type,\n",
    "    vocab_size=embedding_handler.vocab_size,\n",
    "    embedding_dim=config.embedding.embedding_dim,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    config=model_config\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"=\" * 50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training configuration\n",
    "training_config = {\n",
    "    'epochs': config.training.epochs,\n",
    "    'batch_size': config.training.batch_size,\n",
    "    'class_weight': class_weights,\n",
    "    \n",
    "    # Callbacks\n",
    "    'early_stopping': config.training.early_stopping,\n",
    "    'patience': config.training.patience,\n",
    "    'reduce_lr': config.training.reduce_lr,\n",
    "    'lr_factor': config.training.lr_factor,\n",
    "    'lr_patience': config.training.lr_patience,\n",
    "    'min_lr': config.training.min_lr,\n",
    "    'tensorboard': config.training.tensorboard,\n",
    "    'save_best_only': config.training.save_best_only,\n",
    "    'monitor': config.training.monitor,\n",
    "    'mode': config.training.mode,\n",
    "    'verbose': config.training.verbose\n",
    "}\n",
    "\n",
    "# Train model\n",
    "trainer = ModelTrainer(model, config.experiment_name)\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "print(\"=\" * 50)\n",
    "history = trainer.train(X_train, y_train, X_val, y_val, training_config)\n",
    "print(\"\\n✓ Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_results = trainer.evaluate(X_val, y_val)\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in val_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = trainer.predict(X_val)\n",
    "\n",
    "# Create visualizer\n",
    "visualizer = ResultsVisualizer(EMOTION_LABELS)\n",
    "\n",
    "print(\"\\n✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_confusion_matrix(y_val, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_confusion_matrix(y_val, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = visualizer.plot_classification_report(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Prediction Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_prediction_distribution(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_per_class_accuracy(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Complete Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive report\n",
    "create_comprehensive_report(\n",
    "    y_val, y_pred, history,\n",
    "    config.experiment_name,\n",
    "    save_dir='../results'\n",
    ")\n",
    "\n",
    "# Save configuration\n",
    "config.save(f'../configs/{config.experiment_name}_config.yaml')\n",
    "\n",
    "print(\"\\n✓ Complete report and configuration saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions\n",
    "n_samples = 10\n",
    "sample_indices = np.random.choice(len(val_df), n_samples, replace=False)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    text = val_df.iloc[idx]['text']\n",
    "    true_label = np.argmax(y_val[idx])\n",
    "    pred_label = np.argmax(y_pred[idx])\n",
    "    confidence = y_pred[idx][pred_label] * 100\n",
    "    \n",
    "    correct = \"✓\" if true_label == pred_label else \"✗\"\n",
    "    \n",
    "    print(f\"\\n{correct} Text: {text}\")\n",
    "    print(f\"   True: {EMOTION_MAP[true_label]:12s} | Predicted: {EMOTION_MAP[pred_label]:12s} (confidence: {confidence:.1f}%)\")\n",
    "    \n",
    "    # Show top 3 predictions\n",
    "    top3_idx = np.argsort(y_pred[idx])[-3:][::-1]\n",
    "    print(f\"   Top 3: \", end=\"\")\n",
    "    for i, tidx in enumerate(top3_idx):\n",
    "        print(f\"{EMOTION_MAP[tidx]} ({y_pred[idx][tidx]*100:.1f}%)\", end=\"  \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interactive Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text: str, show_probabilities: bool = True):\n",
    "    \"\"\"\n",
    "    Predict emotion for a given text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        show_probabilities: Whether to show all class probabilities\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    cleaned_text = preprocessor.clean_text(text)\n",
    "    \n",
    "    # Convert to sequence\n",
    "    sequence = embedding_handler.texts_to_sequences([cleaned_text])\n",
    "    \n",
    "    # Predict\n",
    "    pred = trainer.predict(sequence)[0]\n",
    "    pred_label = np.argmax(pred)\n",
    "    \n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Cleaned: {cleaned_text}\")\n",
    "    print(f\"\\nPredicted Emotion: {EMOTION_MAP[pred_label]} (confidence: {pred[pred_label]*100:.2f}%)\")\n",
    "    \n",
    "    if show_probabilities:\n",
    "        print(\"\\nAll probabilities:\")\n",
    "        for i, (emotion, prob) in enumerate(zip(EMOTION_LABELS, pred)):\n",
    "            bar = \"█\" * int(prob * 50)\n",
    "            print(f\"  {emotion:12s}: {bar} {prob*100:5.2f}%\")\n",
    "\n",
    "# Test the function\n",
    "test_texts = [\n",
    "    \"I am so happy today!\",\n",
    "    \"This is really frustrating and annoying\",\n",
    "    \"I miss you so much my love\",\n",
    "    \"I am terrified of what might happen\",\n",
    "    \"Oh wow I did not expect that at all!\"\n",
    "]\n",
    "\n",
    "for test_text in test_texts:\n",
    "    predict_emotion(test_text)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Comparison (Optional)\n",
    "\n",
    "Run multiple experiments with different configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section demonstrates how to run multiple experiments\n",
    "# Uncomment to run multiple model comparisons\n",
    "\n",
    "\"\"\"\n",
    "from src.utils.config import get_all_configs\n",
    "\n",
    "# Get predefined configurations\n",
    "all_configs = get_all_configs()\n",
    "\n",
    "results_comparison = {}\n",
    "\n",
    "for config_name, exp_config in all_configs.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running experiment: {config_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Update paths\n",
    "    exp_config.embedding.embedding_path = GLOVE_PATH\n",
    "    \n",
    "    # Create model\n",
    "    # ... (similar to sections above)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    # ... \n",
    "    \n",
    "    # Store results\n",
    "    results_comparison[config_name] = val_results\n",
    "\n",
    "# Compare results\n",
    "visualizer.compare_models(results_comparison)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nTo run model comparison, uncomment the code above and execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete, professional pipeline for emotion detection:\n",
    "\n",
    "1. **Data Processing**: Advanced preprocessing with comprehensive text cleaning\n",
    "2. **Embeddings**: Professional embedding handling with GloVe/Word2Vec support\n",
    "3. **Model Architecture**: Flexible LSTM/GRU models with configurable layers\n",
    "4. **Training**: Complete training pipeline with callbacks and experiment tracking\n",
    "5. **Evaluation**: Comprehensive metrics and professional visualizations\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different hyperparameters\n",
    "- Try bidirectional models or deeper architectures\n",
    "- Compare GloVe vs Word2Vec embeddings\n",
    "- Fine-tune embeddings (set `trainable=True`)\n",
    "- Implement data augmentation for minority classes\n",
    "- Deploy the model as an API\n",
    "\n",
    "All results, models, and configurations are saved in the respective directories for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
